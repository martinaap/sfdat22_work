{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "\n",
    "*Adapted from Chapter 8 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we learning about ensembling?\n",
    "\n",
    "- Very popular method for improving the predictive performance of machine learning models\n",
    "- Provides a foundation for understanding more sophisticated models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson objectives\n",
    "\n",
    "Students will be able to:\n",
    "\n",
    "- Define ensembling and its requirements\n",
    "- Identify the two basic methods of ensembling\n",
    "- Decide whether manual ensembling is a useful approach for a given problem\n",
    "- Explain bagging and how it can be applied to decision trees\n",
    "- Explain how out-of-bag error and feature importances are calculated from bagged trees\n",
    "- Explain the difference between bagged trees and Random Forests\n",
    "- Build and tune a Random Forest model in scikit-learn\n",
    "- Decide whether a decision tree or a Random Forest is a better model for a given problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction\n",
    "\n",
    "Let's pretend that instead of building a single model to solve a binary classification problem, you created **five independent models**, and each model was correct about 70% of the time. If you combined these models into an \"ensemble\" and used their majority vote as a prediction, how often would the ensemble be correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "[1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0]\n",
      "[1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1]\n",
      "[1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0]\n",
      "[0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "\n",
    "# generate 1000 random numbers (between 0 and 1) for each model, representing 1000 observations\n",
    "mod1 = np.random.rand(1000)\n",
    "mod2 = np.random.rand(1000)\n",
    "mod3 = np.random.rand(1000)\n",
    "mod4 = np.random.rand(1000)\n",
    "mod5 = np.random.rand(1000)\n",
    "\n",
    "# each model independently predicts 1 (the \"correct response\") if random number was at least 0.3\n",
    "## predicts something at least 70% of the timmmee. emulating a model that is correct 70% of the time\n",
    "preds1 = np.where(mod1 > 0.3, 1, 0)\n",
    "preds2 = np.where(mod2 > 0.3, 1, 0)\n",
    "preds3 = np.where(mod3 > 0.3, 1, 0)\n",
    "preds4 = np.where(mod4 > 0.3, 1, 0)\n",
    "preds5 = np.where(mod5 > 0.3, 1, 0)\n",
    "\n",
    "# print the first 20 predictions from each model\n",
    "print preds1[:20]\n",
    "print preds2[:20]\n",
    "print preds3[:20]\n",
    "print preds4[:20]\n",
    "print preds5[:20]\n",
    "## each row is the model\n",
    "# each list is all of the observations / predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# average the predictions and then round to 0 or 1\n",
    "ensemble_preds = np.round((preds1 + preds2 + preds3 + preds4 + preds5)/5.0).astype(int)\n",
    "## voting between the 5 of them\n",
    "\n",
    "# print the ensemble's first 20 predictions\n",
    "print ensemble_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713\n",
      "0.665\n",
      "0.717\n",
      "0.712\n",
      "0.687\n"
     ]
    }
   ],
   "source": [
    "# how accurate was each individual model?\n",
    "# each model is on average, correct about 70% of the time\n",
    "print preds1.mean()\n",
    "print preds2.mean()\n",
    "print preds3.mean()\n",
    "print preds4.mean()\n",
    "print preds5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841\n"
     ]
    }
   ],
   "source": [
    "# how accurate was the ensemble?\n",
    "print ensemble_preds.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** As you add more models to the voting process, the probability of error decreases, which is known as [Condorcet's Jury Theorem](http://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is ensembling?\n",
    "\n",
    "**Ensemble learning (or \"ensembling\")** is the process of combining several predictive models in order to produce a combined model that is more accurate than any individual model.\n",
    "\n",
    "- **Regression:** take the average of the predictions\n",
    "- **Classification:** take a vote and use the most common prediction, or take the average of the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different processes\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "There are two basic **methods for ensembling:**\n",
    "\n",
    "- Manually ensemble your individual models\n",
    "- Use a model that ensembles for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Manual ensembling\n",
    "\n",
    "What makes a good manual ensemble?\n",
    "\n",
    "- Different types of **models**\n",
    "- Different combinations of **features**\n",
    "- Different **tuning parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](images/crowdflower_ensembling.jpg)\n",
    "\n",
    "*Machine learning flowchart created by the [winner](https://github.com/ChenglongChen/Kaggle_CrowdFlower) of Kaggle's [CrowdFlower competition](https://www.kaggle.com/c/crowdflower-search-relevance)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing manual ensembling with a single model approach\n",
    "\n",
    "**Advantages of manual ensembling:**\n",
    "\n",
    "- Increases predictive accuracy\n",
    "- Easy to get started\n",
    "\n",
    "**Disadvantages of manual ensembling:**\n",
    "\n",
    "- Decreases interpretability\n",
    "- Takes longer to train\n",
    "- Takes longer to predict\n",
    "- More complex to automate and maintain\n",
    "- Small gains in accuracy may not be worth the added complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Bagging\n",
    "\n",
    "The primary weakness of **decision trees** is that they don't tend to have the best predictive accuracy. This is partially due to **high variance**, meaning that different splits in the training data can lead to very different trees.\n",
    "\n",
    "**Bagging** is a general purpose procedure for reducing the variance of a machine learning method, but is particularly useful for decision trees. Bagging is short for **bootstrap aggregation**, meaning the aggregation of bootstrap samples.\n",
    "\n",
    "What is a **bootstrap sample**? A random sample with replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 6 12 13  9 10 12  6 16  1 17  2 13  8 14  7 19  6 19 12 11]\n"
     ]
    }
   ],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# create an array of 1 through 20\n",
    "nums = np.arange(1, 21)\n",
    "print nums\n",
    "\n",
    "# sample that array 20 times with replacement\n",
    "print np.random.choice(a=nums, size=20, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does bagging work (for decision trees)?**\n",
    "\n",
    "1. Grow B trees using B bootstrap samples from the training data.\n",
    "2. Train each tree on its bootstrap sample and make predictions.\n",
    "3. Combine the predictions:\n",
    "    - Average the predictions for **regression trees**\n",
    "    - Take a vote for **classification trees**\n",
    "\n",
    "Notes:\n",
    "\n",
    "- **Each bootstrap sample** should be the same size as the original training set.\n",
    "- **B** should be a large enough value that the error seems to have \"stabilized\".\n",
    "- The trees are **grown deep** so that they have low bias/high variance.\n",
    "\n",
    "Bagging increases predictive accuracy by **reducing the variance**, similar to how cross-validation reduces the variance associated with train/test split (for estimating out-of-sample error) by splitting many times an averaging the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually implementing bagged decision trees (with B=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>2006</td>\n",
       "      <td>124000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>209000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>138000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  vtype\n",
       "0   22000  2012   13000      2      0\n",
       "1   14000  2010   30000      2      0\n",
       "2   13000  2010   73500      4      0\n",
       "3    9500  2009   78000      4      0\n",
       "4    9000  2007   47000      4      0\n",
       "5    4000  2006  124000      2      0\n",
       "6    3000  2004  177000      4      0\n",
       "7    2000  2004  209000      4      1\n",
       "8    3000  2003  138000      2      0\n",
       "9    1900  2003  160000      4      0\n",
       "10   2500  2003  190000      2      1\n",
       "11   5000  2001   62000      4      0\n",
       "12   1800  1999  163000      2      1\n",
       "13   1300  1997  138000      4      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in and prepare the vehicle training data\n",
    "import pandas as pd\n",
    "url = '../data/vehicles_train.csv'\n",
    "train = pd.read_csv(url)\n",
    "train['vtype'] = train.vtype.map({'car':0, 'truck':1})\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([13,  2, 12,  2,  6,  1,  3, 10, 11,  9,  6,  1,  0,  1]),\n",
       " array([ 9,  0,  0,  9,  3, 13,  4,  0,  0,  4,  1,  7,  3,  2]),\n",
       " array([ 4,  7,  2,  4,  8, 13,  0,  7,  9,  3, 12, 12,  4,  6]),\n",
       " array([ 1,  5,  6, 11,  2,  1, 12,  8,  3, 10,  5,  0, 11,  2]),\n",
       " array([10, 10,  6, 13,  2,  4, 11, 11, 13, 12,  4,  6, 13,  3]),\n",
       " array([10,  0,  6,  4,  7, 11,  6,  7,  1, 11, 10,  5,  7,  9]),\n",
       " array([ 2,  4,  8,  1, 12,  2,  1,  1,  3, 12,  5,  9,  0,  8]),\n",
       " array([11,  1,  6,  3,  3, 11,  5,  9,  7,  9,  2,  3, 11,  3]),\n",
       " array([ 3,  8,  6,  9,  7,  6,  3,  9,  6, 12,  6, 11,  6,  1]),\n",
       " array([13, 10,  3,  4,  3,  1, 13,  0,  5,  8, 13,  6, 11,  8])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "## 14 is the number of observations\n",
    "# create ten bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=14, size=14, replace=True) for _ in range(1, 11)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  vtype\n",
       "13   1300  1997  138000      4      0\n",
       "2   13000  2010   73500      4      0\n",
       "12   1800  1999  163000      2      1\n",
       "2   13000  2010   73500      4      0\n",
       "6    3000  2004  177000      4      0\n",
       "1   14000  2010   30000      2      0\n",
       "3    9500  2009   78000      4      0\n",
       "10   2500  2003  190000      2      1\n",
       "11   5000  2001   62000      4      0\n",
       "9    1900  2003  160000      4      0\n",
       "6    3000  2004  177000      4      0\n",
       "1   14000  2010   30000      2      0\n",
       "0   22000  2012   13000      2      0\n",
       "1   14000  2010   30000      2      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the rows for the first decision tree\n",
    "train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>130000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>2005</td>\n",
       "      <td>82500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000</td>\n",
       "      <td>2010</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  year   miles  doors  vtype\n",
       "0   3000  2003  130000      4      1\n",
       "1   6000  2005   82500      4      0\n",
       "2  12000  2010   60000      2      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in and prepare the vehicle testing data\n",
    "url = '../data/vehicles_test.csv'\n",
    "test = pd.read_csv(url)\n",
    "test['vtype'] = test.vtype.map({'car':0, 'truck':1})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1300.,   5000.,  14000.],\n",
       "       [  1300.,   1300.,  13000.],\n",
       "       [  3000.,   3000.,  13000.],\n",
       "       [  4000.,   5000.,  13000.],\n",
       "       [  1300.,   5000.,  13000.],\n",
       "       [  4000.,   5000.,  14000.],\n",
       "       [  4000.,   4000.,  13000.],\n",
       "       [  4000.,   5000.,  13000.],\n",
       "       [  3000.,   5000.,   9500.],\n",
       "       [  4000.,   5000.,   9000.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# grow each tree deep\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# list for storing predicted price from each tree\n",
    "predictions = []\n",
    "\n",
    "# define testing data\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for sample in samples:\n",
    "    X_train = train.iloc[sample, 1:]\n",
    "    y_train = train.iloc[sample, 0]\n",
    "    treereg.fit(X_train, y_train)\n",
    "    y_pred = treereg.predict(X_test)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "# convert predictions from list to NumPy array\n",
    "predictions = np.array(predictions)\n",
    "predictions  # trained 10 trees on 10 bag samples. each of these 10 trees (rows) predict 3 cars (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2990.,   4330.,  12450.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average predictions\n",
    "np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998.58232843700307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "from sklearn import metrics\n",
    "y_pred = np.mean(predictions, axis=0)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged decision trees in scikit-learn (with B=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the training and testing sets\n",
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instruct BaggingRegressor to use DecisionTreeRegressor as the \"base estimator\"\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "## oob = out of bag - uses the samples not in the original bag set...in the test\n",
    "## b can be too big..not necesarily because it's overfit, but because more noise has been added\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3344.2,   5395. ,  12902. ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and predict\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657.80003040437748"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating out-of-sample error\n",
    "\n",
    "For bagged models, out-of-sample error can be estimated without using **train/test split** or **cross-validation**!\n",
    "\n",
    "On average, each bagged tree uses about **two-thirds** of the observations. For each tree, the **remaining observations** are called \"out-of-bag\" observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  2, 12,  2,  6,  1,  3, 10, 11,  9,  6,  1,  0,  1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first bootstrap sample\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 6, 9, 10, 11, 12, 13])\n",
      "set([0, 1, 2, 3, 4, 7, 9, 13])\n",
      "set([0, 2, 3, 4, 6, 7, 8, 9, 12, 13])\n",
      "set([0, 1, 2, 3, 5, 6, 8, 10, 11, 12])\n",
      "set([2, 3, 4, 6, 10, 11, 12, 13])\n",
      "set([0, 1, 4, 5, 6, 7, 9, 10, 11])\n",
      "set([0, 1, 2, 3, 4, 5, 8, 9, 12])\n",
      "set([1, 2, 3, 5, 6, 7, 9, 11])\n",
      "set([1, 3, 6, 7, 8, 9, 11, 12])\n",
      "set([0, 1, 3, 4, 5, 6, 8, 10, 11, 13])\n"
     ]
    }
   ],
   "source": [
    "# show the \"in-bag\" observations for each sample\n",
    "for sample in samples:\n",
    "    print set(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 7, 8]\n",
      "[5, 6, 8, 10, 11, 12]\n",
      "[1, 5, 10, 11]\n",
      "[4, 7, 9, 13]\n",
      "[0, 1, 5, 7, 8, 9]\n",
      "[2, 3, 8, 12, 13]\n",
      "[6, 7, 10, 11, 13]\n",
      "[0, 4, 8, 10, 12, 13]\n",
      "[0, 2, 4, 5, 10, 13]\n",
      "[2, 7, 9, 12]\n"
     ]
    }
   ],
   "source": [
    "# show the \"out-of-bag\" observations for each sample\n",
    "for sample in samples:\n",
    "    print sorted(set(range(14)) - set(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to calculate **\"out-of-bag error\":**\n",
    "\n",
    "1. For every observation in the training data, predict its response value using **only** the trees in which that observation was out-of-bag. Average those predictions (for regression) or take a vote (for classification).\n",
    "2. Compare all predictions to the actual response values in order to compute the out-of-bag error.\n",
    "\n",
    "When B is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7661434140978729"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the out-of-bag R-squared score (not MSE, unfortunately!) for B=500\n",
    "bagreg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating feature importance\n",
    "\n",
    "Bagging increases **predictive accuracy**, but decreases **model interpretability** because it's no longer possible to visualize the tree to understand the importance of each feature.\n",
    "\n",
    "However, we can still obtain an overall summary of **feature importance** from bagged models:\n",
    "\n",
    "- **Bagged regression trees:** calculate the total amount that **MSE** is decreased due to splits over a given feature, averaged over all trees\n",
    "- **Bagged classification trees:** calculate the total amount that **Gini index** is decreased due to splits over a given feature, averaged over all trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Random Forests\n",
    "\n",
    "Random Forests is a **slight variation of bagged trees** that has even better performance:\n",
    "\n",
    "- Exactly like bagging, we create an ensemble of decision trees using bootstrapped samples of the training set.\n",
    "- However, when building each tree, each time a split is considered, a **random sample of m features** is chosen as split candidates from the **full set of p features**. The split is only allowed to use **one of those m features**.\n",
    "    - A new random sample of features is chosen for **every single tree at every single split**.\n",
    "    - For **classification**, m is typically chosen to be the square root of p.\n",
    "    - For **regression**, m is typically chosen to be somewhere between p/3 and p.\n",
    "\n",
    "What's the point?\n",
    "\n",
    "- Suppose there is **one very strong feature** in the data set. When using bagged trees, most of the trees will use that feature as the top split, resulting in an ensemble of similar trees that are **highly correlated**.\n",
    "- Averaging highly correlated quantities does not significantly reduce variance (which is the entire goal of bagging).\n",
    "- By randomly leaving out candidate features from each split, **Random Forests \"decorrelates\" the trees**, such that the averaging process can reduce the variance of the resulting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Building and tuning decision trees and Random Forests\n",
    "\n",
    "- Major League Baseball player data from 1986-87: [data](https://github.com/justmarkham/DAT8/blob/master/data/hitters.csv), [data dictionary](https://cran.r-project.org/web/packages/ISLR/ISLR.pdf) (page 7)\n",
    "- Each observation represents a player\n",
    "- **Goal:** Predict player salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "url = '../data/hitters.csv'\n",
    "hitters = pd.read_csv(url)\n",
    "\n",
    "# remove rows with missing values\n",
    "hitters.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks  League  Division  PutOuts  Assists  Errors  Salary  NewLeague  \n",
       "1   414     375       0         0      632       43      10   475.0          0  \n",
       "2   266     263       1         0      880       82      14   480.0          1  \n",
       "3   838     354       0         1      200       11       3   500.0          0  \n",
       "4    46      33       0         1      805       40       4    91.5          0  \n",
       "5   336     194       1         0      282      421      25   750.0          1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>495</td>\n",
       "      <td>151</td>\n",
       "      <td>17</td>\n",
       "      <td>61</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>5624</td>\n",
       "      <td>1679</td>\n",
       "      <td>275</td>\n",
       "      <td>884</td>\n",
       "      <td>1015</td>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1045</td>\n",
       "      <td>88</td>\n",
       "      <td>13</td>\n",
       "      <td>2460.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>618</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>110</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>7127</td>\n",
       "      <td>2163</td>\n",
       "      <td>351</td>\n",
       "      <td>1104</td>\n",
       "      <td>1289</td>\n",
       "      <td>564</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2412.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>220</td>\n",
       "      <td>6</td>\n",
       "      <td>2127.333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>677</td>\n",
       "      <td>238</td>\n",
       "      <td>31</td>\n",
       "      <td>117</td>\n",
       "      <td>113</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>2223</td>\n",
       "      <td>737</td>\n",
       "      <td>93</td>\n",
       "      <td>349</td>\n",
       "      <td>401</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1377</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1975.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>514</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>4739</td>\n",
       "      <td>1169</td>\n",
       "      <td>13</td>\n",
       "      <td>583</td>\n",
       "      <td>374</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "      <td>453</td>\n",
       "      <td>15</td>\n",
       "      <td>1940.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>490</td>\n",
       "      <td>125</td>\n",
       "      <td>24</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>6063</td>\n",
       "      <td>1646</td>\n",
       "      <td>271</td>\n",
       "      <td>847</td>\n",
       "      <td>999</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>869</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>1925.571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>614</td>\n",
       "      <td>163</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>5017</td>\n",
       "      <td>1388</td>\n",
       "      <td>266</td>\n",
       "      <td>813</td>\n",
       "      <td>822</td>\n",
       "      <td>617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1900.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>565</td>\n",
       "      <td>148</td>\n",
       "      <td>24</td>\n",
       "      <td>90</td>\n",
       "      <td>104</td>\n",
       "      <td>77</td>\n",
       "      <td>14</td>\n",
       "      <td>7287</td>\n",
       "      <td>2083</td>\n",
       "      <td>305</td>\n",
       "      <td>1135</td>\n",
       "      <td>1234</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1861.460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>551</td>\n",
       "      <td>171</td>\n",
       "      <td>13</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>6090</td>\n",
       "      <td>1840</td>\n",
       "      <td>128</td>\n",
       "      <td>969</td>\n",
       "      <td>900</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1199</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>1800.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>608</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>130</td>\n",
       "      <td>74</td>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>4071</td>\n",
       "      <td>1182</td>\n",
       "      <td>103</td>\n",
       "      <td>862</td>\n",
       "      <td>417</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>426</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1670.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>580</td>\n",
       "      <td>207</td>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>71</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>2778</td>\n",
       "      <td>978</td>\n",
       "      <td>32</td>\n",
       "      <td>474</td>\n",
       "      <td>322</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>267</td>\n",
       "      <td>19</td>\n",
       "      <td>1600.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>441</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>6675</td>\n",
       "      <td>2095</td>\n",
       "      <td>209</td>\n",
       "      <td>1072</td>\n",
       "      <td>1050</td>\n",
       "      <td>695</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>218</td>\n",
       "      <td>16</td>\n",
       "      <td>1500.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>557</td>\n",
       "      <td>142</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>81</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>8759</td>\n",
       "      <td>2583</td>\n",
       "      <td>271</td>\n",
       "      <td>1138</td>\n",
       "      <td>1299</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1160</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>1450.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>627</td>\n",
       "      <td>177</td>\n",
       "      <td>25</td>\n",
       "      <td>98</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>3210</td>\n",
       "      <td>927</td>\n",
       "      <td>133</td>\n",
       "      <td>529</td>\n",
       "      <td>472</td>\n",
       "      <td>313</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>482</td>\n",
       "      <td>13</td>\n",
       "      <td>1350.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>550</td>\n",
       "      <td>147</td>\n",
       "      <td>29</td>\n",
       "      <td>85</td>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>2816</td>\n",
       "      <td>815</td>\n",
       "      <td>117</td>\n",
       "      <td>405</td>\n",
       "      <td>474</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1218</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>1310.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>232</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>4405</td>\n",
       "      <td>1213</td>\n",
       "      <td>194</td>\n",
       "      <td>702</td>\n",
       "      <td>705</td>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>623</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>1300.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>441</td>\n",
       "      <td>118</td>\n",
       "      <td>28</td>\n",
       "      <td>84</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>2723</td>\n",
       "      <td>750</td>\n",
       "      <td>126</td>\n",
       "      <td>433</td>\n",
       "      <td>420</td>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1300.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>610</td>\n",
       "      <td>186</td>\n",
       "      <td>19</td>\n",
       "      <td>107</td>\n",
       "      <td>98</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>2728</td>\n",
       "      <td>753</td>\n",
       "      <td>69</td>\n",
       "      <td>399</td>\n",
       "      <td>366</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1182</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "      <td>1300.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>437</td>\n",
       "      <td>123</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>4139</td>\n",
       "      <td>1203</td>\n",
       "      <td>79</td>\n",
       "      <td>676</td>\n",
       "      <td>390</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>170</td>\n",
       "      <td>15</td>\n",
       "      <td>1260.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>589</td>\n",
       "      <td>170</td>\n",
       "      <td>40</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>2325</td>\n",
       "      <td>634</td>\n",
       "      <td>128</td>\n",
       "      <td>371</td>\n",
       "      <td>376</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1237.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>475</td>\n",
       "      <td>123</td>\n",
       "      <td>27</td>\n",
       "      <td>76</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>1810</td>\n",
       "      <td>471</td>\n",
       "      <td>108</td>\n",
       "      <td>292</td>\n",
       "      <td>343</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1220.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>591</td>\n",
       "      <td>168</td>\n",
       "      <td>19</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>4478</td>\n",
       "      <td>1307</td>\n",
       "      <td>113</td>\n",
       "      <td>634</td>\n",
       "      <td>563</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>1200.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>484</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>3006</td>\n",
       "      <td>844</td>\n",
       "      <td>116</td>\n",
       "      <td>436</td>\n",
       "      <td>458</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1231</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>1183.333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>641</td>\n",
       "      <td>198</td>\n",
       "      <td>31</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>2129</td>\n",
       "      <td>610</td>\n",
       "      <td>92</td>\n",
       "      <td>297</td>\n",
       "      <td>319</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>269</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>1175.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>510</td>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>2872</td>\n",
       "      <td>821</td>\n",
       "      <td>63</td>\n",
       "      <td>307</td>\n",
       "      <td>340</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>810</td>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>1150.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401</td>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>5206</td>\n",
       "      <td>1332</td>\n",
       "      <td>253</td>\n",
       "      <td>784</td>\n",
       "      <td>890</td>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>256</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>7058</td>\n",
       "      <td>1845</td>\n",
       "      <td>312</td>\n",
       "      <td>965</td>\n",
       "      <td>1128</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>1050.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>586</td>\n",
       "      <td>159</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>3082</td>\n",
       "      <td>880</td>\n",
       "      <td>83</td>\n",
       "      <td>363</td>\n",
       "      <td>477</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1043.333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>637</td>\n",
       "      <td>174</td>\n",
       "      <td>31</td>\n",
       "      <td>89</td>\n",
       "      <td>116</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>6727</td>\n",
       "      <td>2024</td>\n",
       "      <td>247</td>\n",
       "      <td>978</td>\n",
       "      <td>1093</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1041.667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>528</td>\n",
       "      <td>132</td>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>2641</td>\n",
       "      <td>671</td>\n",
       "      <td>97</td>\n",
       "      <td>273</td>\n",
       "      <td>383</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>885</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>1008.333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>341</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2964</td>\n",
       "      <td>808</td>\n",
       "      <td>81</td>\n",
       "      <td>379</td>\n",
       "      <td>428</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>512</td>\n",
       "      <td>117</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>1750</td>\n",
       "      <td>412</td>\n",
       "      <td>100</td>\n",
       "      <td>204</td>\n",
       "      <td>276</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1236</td>\n",
       "      <td>98</td>\n",
       "      <td>18</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>298</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>509</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>283</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>438</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>413</td>\n",
       "      <td>92</td>\n",
       "      <td>16</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>413</td>\n",
       "      <td>92</td>\n",
       "      <td>16</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>303</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>468</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>382</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>382</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>97.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>288</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>95.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>633</td>\n",
       "      <td>210</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>3070</td>\n",
       "      <td>872</td>\n",
       "      <td>19</td>\n",
       "      <td>420</td>\n",
       "      <td>230</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>432</td>\n",
       "      <td>16</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>185</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>524</td>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>209</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>216</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>220</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>290</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>90.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>416</td>\n",
       "      <td>113</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>113</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>90.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>268</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>350</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>445</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>618</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>415</td>\n",
       "      <td>16</td>\n",
       "      <td>87.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>181</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>86.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>399</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>670</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>80.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>165</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>323</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>341</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>290</td>\n",
       "      <td>19</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>199</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>514</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>75.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>279</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>205</td>\n",
       "      <td>16</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>216</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>312</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>317</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>122</td>\n",
       "      <td>26</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>185</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>214</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>70.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>215</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>209</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>68.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>181</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>232</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>67.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "100    495   151     17    61   84     78     10    5624   1679     275   \n",
       "163    618   200     20    98  110     62     13    7127   2163     351   \n",
       "217     20     1      0     0    0      0      2      41      9       2   \n",
       "82     677   238     31   117  113     53      5    2223    737      93   \n",
       "229    514   144      0    67   54     79      9    4739   1169      13   \n",
       "112    490   125     24    81  105     62     13    6063   1646     271   \n",
       "84     614   163     29    89   83     75     11    5017   1388     266   \n",
       "96     565   148     24    90  104     77     14    7287   2083     305   \n",
       "179    551   171     13    94   83     94     13    6090   1840     128   \n",
       "248    608   160     28   130   74     89      8    4071   1182     103   \n",
       "313    580   207      8   107   71    105      5    2778    978      32   \n",
       "110    441   128     16    70   73     80     14    6675   2095     209   \n",
       "278    557   142     21    58   81     23     18    8759   2583     271   \n",
       "59     627   177     25    98   81     70      6    3210    927     133   \n",
       "180    550   147     29    85   91     71      6    2816    815     117   \n",
       "142    232    55      9    34   23     45     12    4405   1213     194   \n",
       "177    441   118     28    84   86     68      8    2723    750     126   \n",
       "310    610   186     19   107   98     74      6    2728    753      69   \n",
       "234    437   123      9    62   55     40      9    4139   1203      79   \n",
       "136    589   170     40   107  108     69      6    2325    634     128   \n",
       "91     475   123     27    76   93     72      4    1810    471     108   \n",
       "53     591   168     19    80   72     39      9    4478   1307     113   \n",
       "189    484   127     20    66   65     67      7    3006    844     116   \n",
       "108    641   198     31   101  108     41      5    2129    610      92   \n",
       "300    510   147     10    56   52     53      7    2872    821      63   \n",
       "9      401    92     17    49   66     65     13    5206   1332     253   \n",
       "243    256    70     13    42   36     44     16    7058   1845     312   \n",
       "184    586   159     12    72   79     53      9    3082    880      83   \n",
       "86     637   174     31    89  116     56     14    6727   2024     247   \n",
       "145    528   132     21    61   74     41      6    2641    671      97   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "153    341    95      6    48   42     20     10    2964    808      81   \n",
       "272    512   117     29    54   88     43      6    1750    412     100   \n",
       "7      298    73      0    24   24      7      3     509    108       0   \n",
       "139    438   103      2    65   32     71      2     440    103       2   \n",
       "20     413    92     16    72   48     65      1     413     92      16   \n",
       "213    303    71      3    18   30     36      3     344     76       3   \n",
       "266    382   101     16    50   55     22      1     382    101      16   \n",
       "151    151    41      4    26   21     19      2     288     68       9   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "282    633   210      6    91   56     59      6    3070    872      19   \n",
       "135    185    40      4    23   11     18      3     524    125       7   \n",
       "205    209    56     12    22   36     19      2     216     58      12   \n",
       "273    220    66      5    20   28     13      3     290     80       5   \n",
       "60     416   113     24    58   69     16      1     416    113      24   \n",
       "37     268    60      5    24   25     15      2     350     78       5   \n",
       "133    445    99      1    46   24     29      4     618    129       1   \n",
       "176    181    58      6    34   23     22      1     181     58       6   \n",
       "155    399   102      3    56   34     34      5     670    167       4   \n",
       "162    165    39      2    13    9     16      3     196     44       2   \n",
       "8      323    81      6    26   32      8      2     341     86       6   \n",
       "67     199    53      5    29   22     21      3     514    120       8   \n",
       "188    279    64      0    31   26     30      1     279     64       0   \n",
       "201    216    54      2    27   25     33      1     216     54       2   \n",
       "259    312    68      2    32   22     24      1     312     68       2   \n",
       "92     317    78      7    35   35     32      1     317     78       7   \n",
       "6      185    37      1    23    8     21      2     214     42       1   \n",
       "51     214    53      2    30   29     23      2     226     59       2   \n",
       "109    215    51      4    19   18     11      1     215     51       4   \n",
       "212    209    54      3    25   14     12      1     209     54       3   \n",
       "40     181    41      1    15   21     33      2     232     50       4   \n",
       "\n",
       "     CRuns  CRBI  CWalks  League  Division  PutOuts  Assists  Errors  \\\n",
       "100    884  1015     709       1         1     1045       88      13   \n",
       "163   1104  1289     564       1         1      330       16       8   \n",
       "217      6     7       4       0         1       78      220       6   \n",
       "82     349   401     171       1         1     1377      100       6   \n",
       "229    583   374     528       0         1      229      453      15   \n",
       "112    847   999     680       0         1      869       62       8   \n",
       "84     813   822     617       0         0      303        6       6   \n",
       "96    1135  1234     791       1         1      292        9       5   \n",
       "179    969   900     917       0         1     1199      149       5   \n",
       "248    862   417     708       1         1      426        4       6   \n",
       "313    474   322     417       1         1      121      267      19   \n",
       "110   1072  1050     695       1         0       97      218      16   \n",
       "278   1138  1299     478       0         0     1160       53       7   \n",
       "59     529   472     313       1         1      240      482      13   \n",
       "180    405   474     319       1         0     1218      104      10   \n",
       "142    702   705     625       0         1      623       35       3   \n",
       "177    433   420     309       1         1      190        2       2   \n",
       "310    399   366     286       0         1     1182       96      13   \n",
       "234    676   390     364       1         1       82      170      15   \n",
       "136    371   376     238       1         1      368       20       3   \n",
       "91     292   343     267       0         1      226       10       6   \n",
       "53     634   563     319       1         0       67      147       4   \n",
       "189    436   458     377       0         1     1231       80       7   \n",
       "108    297   319     117       1         1      269       17      10   \n",
       "300    307   340     174       0         1      810       99      18   \n",
       "9      784   890     866       1         1        0        0       0   \n",
       "243    965  1128     990       0         1       41      118       8   \n",
       "184    363   477     295       0         1      181       13       4   \n",
       "86     978  1093     495       0         0      278        9       9   \n",
       "145    273   383     226       0         1      885      105       8   \n",
       "..     ...   ...     ...     ...       ...      ...      ...     ...   \n",
       "153    379   428     221       0         0      158        4       5   \n",
       "272    204   276     155       1         0     1236       98      18   \n",
       "7       41    37      12       1         0      121      283       9   \n",
       "139     67    32      71       1         0      276        7       9   \n",
       "20      72    48      65       0         1      280        9       5   \n",
       "213     20    36      45       0         1      468       47       6   \n",
       "266     50    55      22       1         0      200        7       6   \n",
       "151     45    39      35       1         0       28       56       2   \n",
       "4       48    46      33       0         1      805       40       4   \n",
       "282    420   230     274       0         0      367      432      16   \n",
       "135     58    37      47       0         1       97        2       2   \n",
       "205     24    37      19       0         1      201        6       3   \n",
       "273     27    31      15       1         0      281       21       3   \n",
       "60      58    69      16       1         1      203       70      10   \n",
       "37      34    29      18       0         0      442       59       6   \n",
       "133     72    31      48       1         0      278      415      16   \n",
       "176     34    23      22       0         0       88        0       3   \n",
       "155     89    48      54       1         0      211        9       3   \n",
       "162     18    10      18       1         0      332       19       2   \n",
       "8       32    34       8       0         0      143      290      19   \n",
       "67      57    40      39       1         0      152        3       5   \n",
       "188     31    26      30       0         0      107      205      16   \n",
       "201     27    25      33       0         0      317       36       1   \n",
       "259     32    22      24       1         1       86      150      15   \n",
       "92      35    35      32       1         1       45      122      26   \n",
       "6       30     9      24       0         1       76      127       7   \n",
       "51      32    32      27       0         1      109        7       3   \n",
       "109     19    18      11       1         1      116        5      12   \n",
       "212     25    14      12       1         0      102        6       3   \n",
       "40      20    29      45       1         1      326       29       5   \n",
       "\n",
       "       Salary  NewLeague  \n",
       "100  2460.000          1  \n",
       "163  2412.500          1  \n",
       "217  2127.333          0  \n",
       "82   1975.000          1  \n",
       "229  1940.000          0  \n",
       "112  1925.571          0  \n",
       "84   1900.000          0  \n",
       "96   1861.460          1  \n",
       "179  1800.000          0  \n",
       "248  1670.000          1  \n",
       "313  1600.000          1  \n",
       "110  1500.000          1  \n",
       "278  1450.000          0  \n",
       "59   1350.000          1  \n",
       "180  1310.000          1  \n",
       "142  1300.000          0  \n",
       "177  1300.000          1  \n",
       "310  1300.000          0  \n",
       "234  1260.000          1  \n",
       "136  1237.500          1  \n",
       "91   1220.000          0  \n",
       "53   1200.000          1  \n",
       "189  1183.333          0  \n",
       "108  1175.000          1  \n",
       "300  1150.000          0  \n",
       "9    1100.000          1  \n",
       "243  1050.000          1  \n",
       "184  1043.333          0  \n",
       "86   1041.667          0  \n",
       "145  1008.333          0  \n",
       "..        ...        ...  \n",
       "153   100.000          0  \n",
       "272   100.000          1  \n",
       "7     100.000          1  \n",
       "139   100.000          0  \n",
       "20    100.000          0  \n",
       "213   100.000          0  \n",
       "266    97.500          1  \n",
       "151    95.000          1  \n",
       "4      91.500          0  \n",
       "282    90.000          0  \n",
       "135    90.000          0  \n",
       "205    90.000          0  \n",
       "273    90.000          1  \n",
       "60     90.000          1  \n",
       "37     90.000          0  \n",
       "133    87.500          1  \n",
       "176    86.500          0  \n",
       "155    80.000          1  \n",
       "162    75.000          0  \n",
       "8      75.000          0  \n",
       "67     75.000          1  \n",
       "188    75.000          0  \n",
       "201    75.000          0  \n",
       "259    70.000          1  \n",
       "92     70.000          1  \n",
       "6      70.000          1  \n",
       "51     70.000          0  \n",
       "109    70.000          1  \n",
       "212    68.000          1  \n",
       "40     67.500          1  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.sort_values('Salary',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks  League  Division  PutOuts  Assists  Errors  Salary  NewLeague  \n",
       "1   414     375       0         0      632       43      10   475.0          0  \n",
       "2   266     263       1         0      880       82      14   480.0          1  \n",
       "3   838     354       0         1      200       11       3   500.0          0  \n",
       "4    46      33       0         1      805       40       4    91.5          0  \n",
       "5   336     194       1         0      282      421      25   750.0          1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode categorical variables as integers\n",
    "hitters['League'] = pd.factorize(hitters.League)[0]\n",
    "hitters['Division'] = pd.factorize(hitters.Division)[0]\n",
    "hitters['NewLeague'] = pd.factorize(hitters.NewLeague)[0]\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of Years versus Hits colored by Salary\n",
    "# hitters.plot(kind='scatter', x='Years', y='Hits', c='Salary', xlim=(0, 25), ylim=(0, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AtBat',\n",
       " 'Hits',\n",
       " 'HmRun',\n",
       " 'Runs',\n",
       " 'RBI',\n",
       " 'Walks',\n",
       " 'Years',\n",
       " 'League',\n",
       " 'Division',\n",
       " 'PutOuts',\n",
       " 'Assists',\n",
       " 'Errors',\n",
       " 'NewLeague']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define features: exclude career statistics (which start with \"C\") and the response (Salary)\n",
    "feature_cols = [h for h in hitters.columns if h[0] != 'C' and h != 'Salary']\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = hitters[feature_cols]\n",
    "y = hitters.Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting salary with a decision tree\n",
    "\n",
    "Find the best **max_depth** for a decision tree using cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_depth\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# list to store the average RMSE for each value of max_depth\n",
    "RMSE_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_depth\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "for depth in max_depth_range:\n",
    "    treereg = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    MSE_scores = cross_val_score(treereg, X, y, cv=10, scoring='mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11775b350>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEQCAYAAABFtIg2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1176ede10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340.03416870475201, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best RMSE and the corresponding max_depth\n",
    "sorted(zip(RMSE_scores, max_depth_range))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_depth=2 was best, so fit a tree using that parameter\n",
    "treereg = DecisionTreeRegressor(max_depth=2, random_state=1)\n",
    "treereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Runs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RBI</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walks</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>League</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Division</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Assists</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Errors</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NewLeague</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Years</td>\n",
       "      <td>0.488391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hits</td>\n",
       "      <td>0.511609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "0       AtBat    0.000000\n",
       "2       HmRun    0.000000\n",
       "3        Runs    0.000000\n",
       "4         RBI    0.000000\n",
       "5       Walks    0.000000\n",
       "7      League    0.000000\n",
       "8    Division    0.000000\n",
       "9     PutOuts    0.000000\n",
       "10    Assists    0.000000\n",
       "11     Errors    0.000000\n",
       "12  NewLeague    0.000000\n",
       "6       Years    0.488391\n",
       "1        Hits    0.511609"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute feature importances\n",
    "## only 2 of them show up because it only asked 3 questions, and one of them got asked twice\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treereg.feature_importances_}).sort('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting salary with a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfreg = RandomForestRegressor()\n",
    "rfreg\n",
    "## criterion - decides score, decides the best split (what is the best split) (e.g. accuracy, gini index, entropy)\n",
    "## n is the number of trees you want to train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators\n",
    "\n",
    "One important tuning parameter is **n_estimators**, which is the number of trees that should be grown. It should be a large enough value that the error seems to have \"stabilized\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of values to try for n_estimators\n",
    "## COULD HAVE USED GRID SEARCH\n",
    "estimator_range = range(10, 310, 10) # 10 to 320 decision trees, in groups of 10 (10,20, 30,....300). THIS IS 30 TREES BECAUSE IT IS NOT INCLUSIVE  OF 310\n",
    "\n",
    "# list to store the average RMSE for each value of n_estimators\n",
    "RMSE_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of n_estimators (WARNING: SLOW!)\n",
    "for estimator in estimator_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=estimator, random_state=1)\n",
    "    MSE_scores = cross_val_score(rfreg, X, y, cv=5, scoring='mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11a8c39d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEQCAYAAACjnUNyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVN5qnbaBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1176f6450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot n_estimators (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(estimator_range, RMSE_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300]\n"
     ]
    }
   ],
   "source": [
    "print (estimator_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features\n",
    "\n",
    "The other important tuning parameter is **max_features**, which is the number of features that should be considered at each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = range(1, len(feature_cols)+1)\n",
    "\n",
    "# list to store the average RMSE for each value of max_features\n",
    "RMSE_scores = []\n",
    "\n",
    "# max features means you get x features instead of all columns to pick from randomly\n",
    "# use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for feature in feature_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=150, max_features=feature, random_state=1)\n",
    "    MSE_scores = cross_val_score(rfreg, X, y, cv=10, scoring='mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11a8c26d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEQCAYAAABFtIg2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa02b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot max_features (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(feature_range, RMSE_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290.00785113284348, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best RMSE and the corresponding max_features\n",
    "sorted(zip(RMSE_scores, feature_range))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Random Forest with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=8, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=150, n_jobs=1, oob_score=True, random_state=1,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features=8 is best and n_estimators=150 is sufficiently large\n",
    "rfreg = RandomForestRegressor(n_estimators=150, max_features=8, oob_score=True, random_state=1)\n",
    "rfreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>League</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NewLeague</td>\n",
       "      <td>0.004290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Division</td>\n",
       "      <td>0.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Assists</td>\n",
       "      <td>0.023842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Errors</td>\n",
       "      <td>0.028618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>0.044607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>0.060063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Runs</td>\n",
       "      <td>0.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>0.094592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RBI</td>\n",
       "      <td>0.130965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walks</td>\n",
       "      <td>0.139899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hits</td>\n",
       "      <td>0.145264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Years</td>\n",
       "      <td>0.246980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "7      League    0.003603\n",
       "12  NewLeague    0.004290\n",
       "8    Division    0.005477\n",
       "10    Assists    0.023842\n",
       "11     Errors    0.028618\n",
       "2       HmRun    0.044607\n",
       "9     PutOuts    0.060063\n",
       "3        Runs    0.071800\n",
       "0       AtBat    0.094592\n",
       "4         RBI    0.130965\n",
       "5       Walks    0.139899\n",
       "1        Hits    0.145264\n",
       "6       Years    0.246980"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':rfreg.feature_importances_}).sort('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52741870027692672"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the out-of-bag R-squared score\n",
    "rfreg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing X to its most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 13)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 4)\n",
      "(263, 5)\n",
      "(263, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## this is called pruning or back propagation\n",
    "\n",
    "# set a threshold for which features to include\n",
    "print rfreg.transform(X, threshold=0.1).shape ## include ony 1% of features (kill the ones less than 0.1)\n",
    "print rfreg.transform(X, threshold='mean').shape  # include features better than the mean\n",
    "print rfreg.transform(X, threshold='median').shape  # include features that are better than the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# create a new feature matrix that only includes important features\n",
    "X_important = rfreg.transform(X, threshold='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284.35550515135395"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the RMSE for a Random Forest that only includes important features\n",
    "rfreg = RandomForestRegressor(n_estimators=150, max_features=3, random_state=1)\n",
    "scores = cross_val_score(rfreg, X_important, y, cv=10, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Random Forests with decision trees\n",
    "\n",
    "**Advantages of Random Forests:**\n",
    "\n",
    "- Performance is competitive with the best supervised learning methods\n",
    "- Provides a more reliable estimate of feature importance\n",
    "- Allows you to estimate out-of-sample error without using train/test split or cross-validation\n",
    "\n",
    "**Disadvantages of Random Forests:**\n",
    "\n",
    "- Less interpretable\n",
    "- Slower to train\n",
    "- Slower to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](images/driver_ensembling.png)\n",
    "\n",
    "*Machine learning flowchart created by the [second place finisher](http://blog.kaggle.com/2015/04/20/axa-winners-interview-learning-telematic-fingerprints-from-gps-data/) of Kaggle's [Driver Telematics competition](https://www.kaggle.com/c/axa-driver-telematics-analysis)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
